{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom transformers import BertTokenizer, BertForSequenceClassification, GPT2LMHeadModel, GPT2Tokenizer","metadata":{"execution":{"iopub.status.busy":"2023-08-06T12:50:14.938474Z","iopub.status.idle":"2023-08-06T12:50:14.939451Z","shell.execute_reply.started":"2023-08-06T12:50:14.939128Z","shell.execute_reply":"2023-08-06T12:50:14.939158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Loading tokenizer for bert\nbert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n#loading bert sequence classification model\nbert_model = BertForSequenceClassification.from_pretrained('bert-base-uncased')","metadata":{"execution":{"iopub.status.busy":"2023-08-06T12:50:14.941371Z","iopub.status.idle":"2023-08-06T12:50:14.941894Z","shell.execute_reply.started":"2023-08-06T12:50:14.941681Z","shell.execute_reply":"2023-08-06T12:50:14.941703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Loading tokenizer for gpt2\ngpt2_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n#loading gpt2 model\ngpt2_model = GPT2LMHeadModel.from_pretrained('gpt2')","metadata":{"execution":{"iopub.status.busy":"2023-08-06T12:50:14.943310Z","iopub.status.idle":"2023-08-06T12:50:14.945092Z","shell.execute_reply.started":"2023-08-06T12:50:14.944861Z","shell.execute_reply":"2023-08-06T12:50:14.944885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Defining intent labels for basic chat\nintent_labels = [\"greeting\", \"goodbye\", \"question\"]","metadata":{"execution":{"iopub.status.busy":"2023-08-06T12:50:14.946706Z","iopub.status.idle":"2023-08-06T12:50:14.947112Z","shell.execute_reply.started":"2023-08-06T12:50:14.946911Z","shell.execute_reply":"2023-08-06T12:50:14.946930Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# classify intent using BERT\ndef classify_intent(user_input):\n    inputs = bert_tokenizer.encode(user_input, add_special_tokens=True, max_length=128, truncation=True)\n    with torch.no_grad():\n        outputs = bert_model(torch.tensor(inputs).unsqueeze(0))[0]\n        predicted_label = intent_labels[torch.argmax(outputs).item()]\n    return predicted_label\n\n# generate response using GPT2\ndef generate_response(prompt):\n    input_ids = gpt2_tokenizer.encode(prompt, add_special_tokens=True, max_length=128, truncation=True)\n    with torch.no_grad():\n        output = gpt2_model(torch.tensor(input_ids).unsqueeze(0))[0]\n    response = gpt2_tokenizer.decode(output[0], skip_special_tokens=True)\n    return response","metadata":{"execution":{"iopub.status.busy":"2023-08-06T12:50:14.948717Z","iopub.status.idle":"2023-08-06T12:50:14.949123Z","shell.execute_reply.started":"2023-08-06T12:50:14.948931Z","shell.execute_reply":"2023-08-06T12:50:14.948950Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Hello type exit to end \")\nwhile True:\n    user_input = input(\"You: \")\n    if user_input.lower() == 'exit':\n        print(\"Bye!\")\n        break\n    intent = classify_intent(user_input)\n    if intent == \"greeting\":\n        response = \"Greetings! How can I assist you?\"\n    elif intent == \"goodbye\":\n        response = \"Goodbye!\"\n    elif intent == \"question\":\n        response = \"I'm sorry, but I'm not able to answer questions\"\n    else:\n        response = generate_response(user_input)\n    print(\"Chatbot:\", response)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-06T12:50:14.950334Z","iopub.status.idle":"2023-08-06T12:50:14.950864Z","shell.execute_reply.started":"2023-08-06T12:50:14.950536Z","shell.execute_reply":"2023-08-06T12:50:14.950671Z"},"trusted":true},"execution_count":null,"outputs":[]}]}